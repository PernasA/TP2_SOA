{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cuaderno_2_Martes_grupo6a_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpVFx/0j0wnlIbFrph4A4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PernasA/TP2_SOA/blob/master/HPC/Cuaderno_2_Martes_grupo6a_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKrwBVk-OuKG"
      },
      "source": [
        "\n",
        "### 1. Introducción\n",
        "\n",
        "El Ejercicio 2 del TP3 tiene como objetivo probar la diferencia de velocidad de procesamiento que hay entre procesamiento secuencial con paralelo. Para ello, se generará un vector con valores enteros aleatorios y se pedirá al usuario que defina el tamaño del mismo. También se le solicitará que ingrese el número que se quiere buscar en el vector.\n",
        "Con estos datos, el programa buscará al elemento y si lo encuentra dirá cuál fue la última posición donde apareció.\n",
        "\n",
        "### 2. Armado del ambiente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HmEDSAeWKpJ"
      },
      "source": [
        " #@markdown ### Seleccione el número a buscar:\n",
        " nro_a_buscar = 21 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Seleccione el tamaño del vector:\n",
        "tam_vector = 200000 #@param {type:\"slider\", min:1, max:200000, step:10}\n"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3IywKY4f_T5"
      },
      "source": [
        "### 3. Desarrollo\n",
        "# CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usyxvldvgHiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "outputId": "c44bae28-a3e6-4766-9aa3-fc4aceb25da8"
      },
      "source": [
        "#--------------------------------------BIBLIOTECAS--------------------------------------#\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import numpy\n",
        "import sys\n",
        "try:\n",
        "\n",
        "  #@title Ingrese la url de una imagen:\n",
        "  #Obtencion del tiempo inicial\n",
        "  tiempo_total = datetime.now()\n",
        "  \n",
        "  #Declaracion de funcion que realiza el pasaje del tiempo obtenido mediante datetime.now(), a milisegundos.\n",
        "  tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "  #---------------------------------------CODIGO--------------------------------------------#\n",
        "  # Definimos el vector y lo cargamos con valores aleatorios del 0 al 100\n",
        "\n",
        "  vector_cpu= numpy.random.randint(0, 100, size = tam_vector)\n",
        "  vector_cpu = vector_cpu.astype(numpy.int32())\n",
        "\n",
        "  #print(\"El vector es: \",vector_cpu.tolist())\n",
        "\n",
        "  tiempo_cpu = datetime.now()\n",
        "\n",
        "  #Algoritmo aplicado en cpu\n",
        "  ultima_aparicion = -1\n",
        "  contador = 1\n",
        "  for numero in vector_cpu:\n",
        "    contador+=1\n",
        "    if numero == nro_a_buscar:\n",
        "      ultima_aparicion += contador\n",
        "\n",
        "\n",
        "\n",
        "  print( \"Cantidad de elementos:\", len(vector_cpu) )\n",
        "  print(\"Tiempo CPU:\", tiempo_en_ms( datetime.now() - tiempo_cpu   ), \"[ms]\" )\n",
        "\n",
        "  if ultima_aparicion != -1:\n",
        "    print(\"Se encontró por CPU el valor:\",nro_a_buscar)\n",
        "    print(\"La última posición donde aparece es:\", ultima_aparicion)\n",
        "  else:\n",
        "    print(\"No se encontró por CPU el valor:\",nro_a_buscar)\n",
        "\n",
        "  #Calculo del tiempo total de procesamiento de la imagen en CPU\n",
        "  tiempo_cpu = datetime.now() - tiempo_cpu\n",
        "\n",
        "  #Calculo del tiempo total de ejecucion del programa\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print(\"Tiempo total de ejecucion: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "  print(\"Tiempo de procesamiento en CPU: \", tiempo_en_ms( tiempo_cpu   ), \"[ms]\" )\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Error\", e )\n",
        "  sys.exit()"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de elementos: 200000\n",
            "Tiempo CPU: 332.529 [ms]\n",
            "Se encontró por CPU el valor: 21\n",
            "La última posición donde aparece es: 197517393\n",
            "Tiempo total de ejecucion:  336.746 [ms]\n",
            "Tiempo de procesamiento en CPU:  333.374 [ms]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KftbwH-XvUJA"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR_CGq9Yvt1s",
        "outputId": "4cc63ba3-00be-433c-943e-f9ed0de32118"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2021.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.1.6)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2021.2.9)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bWB3jOfvmnO",
        "outputId": "784cf1e4-942d-436a-d984-ca8c2e9f83ec"
      },
      "source": [
        "#try:\n",
        "%matplotlib inline\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# Definimos el vector y lo cargamos con valores aleatorios del 0 al 100\n",
        "valor_aux = numpy.zeros((tam_vector,), dtype=int);\n",
        "valor_aux = valor_aux.astype(numpy.int32())\n",
        "\n",
        "vector_cpu= numpy.random.randint(0, 100, size = tam_vector)\n",
        "\n",
        "vector_cpu = vector_cpu.astype(numpy.int32())\n",
        "\n",
        "vec_ult_pos_cpu= numpy.empty_like(valor_aux)\n",
        "\n",
        "#Reservo memoria en los vectores de gpu\n",
        "vec_ult_aparicion_gpu = cuda.mem_alloc(vec_ult_pos_cpu.nbytes)\n",
        "vector_gpu               = cuda.mem_alloc( vector_cpu.nbytes )\n",
        "\n",
        "#Copio la memoria al gpu\n",
        "cuda.memcpy_htod( vec_ult_aparicion_gpu, valor_aux)\n",
        "cuda.memcpy_htod( vector_gpu, vector_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_axpy( int tam_vector, int *vector, int nro_a_buscar, int *cant_apariciones )\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < tam_vector )\n",
        "  {\n",
        "    if (vector[idx] == nro_a_buscar) {\n",
        "      cant_apariciones[idx]+=1;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"kernel_axpy\")\n",
        "\n",
        "tiempo_GPU_img = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "dim_hilo = 100\n",
        "dim_bloque = numpy.int( (len(vector_cpu)+dim_hilo-1) / dim_hilo )\n",
        "\n",
        "#print(\"el vector de cpu es: \",vector_cpu.tolist())\n",
        "\n",
        "#TODO: Ojo, con los tipos de las variables en el kernel.\n",
        "kernel( numpy.int32(len(vector_cpu)), vector_gpu, \n",
        "        numpy.int32(nro_a_buscar), \n",
        "        vec_ult_aparicion_gpu,\n",
        "        block=( dim_hilo, 1, 1 ),\n",
        "        grid= (dim_bloque, 1, 1) )\n",
        "\n",
        "cuda.memcpy_dtoh( vec_ult_pos_cpu, vec_ult_aparicion_gpu )\n",
        "\n",
        "result= vec_ult_pos_cpu.tolist()\n",
        "#print(\"el vector resultado es: \",result)\n",
        "\n",
        "\n",
        "print( \"Cantidad de elementos:\", len(vector_cpu) )\n",
        "print( \"Thread x:\", dim_hilo,\", Bloque x:\", dim_bloque )\n",
        "\n",
        "ult_posicion = -1\n",
        "contador_fin = 1\n",
        "for numero in result:\n",
        "  contador_fin += 1\n",
        "  if numero == 1:\n",
        "    ult_posicion = contador_fin\n",
        "\n",
        "if ult_posicion != -1:\n",
        "  print(\"Se encontró por GPU el valor:\",nro_a_buscar)\n",
        "  print(\"La última posición donde aparece es:\",ult_posicion)\n",
        "else:\n",
        "  print(\"No se encontró por GPU el valor:\",nro_a_buscar)\n",
        "\n",
        "tiempo_GPU_img = datetime.now() - tiempo_GPU_img\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print(\"Tiempo TOTAL: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU  : \", tiempo_en_ms( tiempo_GPU_img ), \"[ms]\" )\n",
        "# except Exception as e:\n",
        "#   print(\"Error: \", e)\n",
        "#   sys.exit()"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de elementos: 200000\n",
            "Thread x: 100 , Bloque x: 2000\n",
            "Se encontró por GPU el valor: 21\n",
            "La última posición donde aparece es: 199994\n",
            "Tiempo TOTAL:  39.457 [ms]\n",
            "Tiempo GPU  :  30.692 [ms]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohHjPgTMcF01"
      },
      "source": [
        "# 4. Métricas\n",
        "\n",
        "Cant Elementos|Tiempo GPU | Tiempo CPU \n",
        "--------|-----------|------------------\n",
        "10|2.934 [ms]      | 2.274 [ms]\n",
        "1.000| 3.411[ms]     | 3.509 [ms]\n",
        "10.000| 6.267 [ms]      |17.849 [ms]\n",
        "100.000|30.502 [ms]       | 159.546 [ms]\n",
        "200.000|53.803 [ms]       | 399.014 [ms]\n",
        "\n",
        "\n",
        "Tiempo promedio GPU |\tTiempo promedio CPU\n",
        "-------------------|------------------\n",
        "16.15 ms | 97,2 ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNX8jzs26Dlz"
      },
      "source": [
        "\n",
        "# 4. Conclusiones\n",
        "\n",
        "Observando las metricas, podemos concluir que el procesamiento de la imagen en GPU se realiza más rapido que en CPU a medida que aumenta el tamaño del vector. Al inicio, incluso es más rápido el tiempo en cpu en un vector de tamaño 10. Sin embargo, ya cuando el vector es de 200.000 elementos, el tiempo en gpu es 4 veces más chico. Esto demuestra cómo el procesamiento paralelo es mucho mejor que el secuencial a medida que hay más datos para procesar. \n",
        "Otro punto a tener en cuenta fue la dificultad de implementar los algoritmos en gpu, mientras que en cpu es un simple loop.\n",
        "\n",
        "# 5. Bibliografía\n",
        "\n",
        "[1] Manejo de vectores -Numpy: https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
        "\n",
        "\n",
        "[2] Cuda - Documentación Oficial Nvidia:  https://docs.nvidia.com/cuda/\n",
        "\n",
        "[3] Python basico UNLaM: https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFrvTMJq6Kcz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}